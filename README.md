Welcome to Coderamp!

This environment is preconfigured with Ollama, 
Ollama lets you easily run AI models locally

Here, you can try-out small models, view their responses, and experiment freely. 

You can start from the provided code in main.py
Run `python3 main.py`  in the terminal 

Have fun!

Disclaimer:
This environment is CPU-based and supports only small models
It's temporary and will automatically close one hour after opening

Your feedback is invaluable!
Feel free to reach out at romain@coderamp.io
